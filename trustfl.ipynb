{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.utils.data\n",
    "from torch import nn\n",
    "import torchvision, torchvision.datasets\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "\n",
    "from fedlab.main.fedlab_benchmarks.leaf.dataloader import get_LEAF_dataloader\n",
    "\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import time\n",
    "from sklearn.metrics import f1_score   \n",
    "import numpy as np\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu117\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_femnist_shakespeare_dataset(**args):\n",
    "    if args['dataset'] == 'femnist' or args['dataset'] == 'shakespeare':\n",
    "        trainloader, testloader = get_LEAF_dataloader(dataset=args['dataset'],\n",
    "                                                      client_id=args['rank'])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset:\", args['dataset'])\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000002EDBFC0B160>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000002ED074E6770>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000002ED074E61A0>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000002ED074E6080>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000002ED074E7370>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loaders = []\n",
    "test_loaders = []\n",
    "num_nodes = 5\n",
    "num_class = 62\n",
    "epoch_total = 1\n",
    "\n",
    "for i in range(num_nodes):\n",
    "    args = {'dataset': 'femnist', 'rank': i}\n",
    "    trainloader, testloader = get_femnist_shakespeare_dataset(**args)\n",
    "    train_loaders.append(trainloader)\n",
    "    test_loaders.append(testloader)\n",
    "\n",
    "#loader = zip(train_loaders, test_loaders)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "[<torch.utils.data.dataloader.DataLoader object at 0x000002EDBFC0B2B0>, <torch.utils.data.dataloader.DataLoader object at 0x000002ED074E5B40>, <torch.utils.data.dataloader.DataLoader object at 0x000002ED074E7160>, <torch.utils.data.dataloader.DataLoader object at 0x000002ED074E5B70>, <torch.utils.data.dataloader.DataLoader object at 0x000002ED074E7C40>]\n",
      "343\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loaders))\n",
    "print(len(test_loaders))\n",
    "print(test_loaders)\n",
    "print(len(train_loaders[0].dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3070 Ti Laptop GPU'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "torch.cuda.get_device_name(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "target_transform = lambda x: torch.nn.functional.one_hot(torch.tensor(x),num_class).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_i_j = {}\n",
    "s_i = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FederatedNode:\n",
    "    def __init__(self, train_dataloader, test_dataloader, node_id) -> None:\n",
    "        self.dataset_size = len(train_dataloader.dataset)\n",
    "        channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "        for data, _ in train_dataloader:\n",
    "            # Mean over batch, height and width, but not over the channels\n",
    "            channels_sum += torch.mean(data, dim=[0])\n",
    "            channels_squared_sum += torch.mean(data**2, dim=[0])\n",
    "            num_batches += 1\n",
    "    \n",
    "        self.mean = channels_sum / num_batches\n",
    "        self.test_loss = 0.0\n",
    "        self.test_accuracy = 0.0\n",
    "        self.train_accuracy = 0.0\n",
    "        self.f1_score = 0.0\n",
    "\n",
    "\n",
    "        # std = sqrt(E[X^2] - (E[X])^2)\n",
    "        self.std = (channels_squared_sum / num_batches - self.mean ** 2) ** 0.5\n",
    "        print(\"Dataset size \", self.dataset_size)\n",
    "        print(\"Mean size \", self.mean.shape)\n",
    "        print(\"Standard deviation size \", self.std.shape)\n",
    "        \n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(784,56),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(56, num_class)\n",
    "        ).to(device)\n",
    "\n",
    "        '''\n",
    "        only_digits=False\n",
    "        self.network = nn.Sequential(\n",
    "        nn.Conv2d(1, 32, kernel_size=3),\n",
    "        nn.MaxPool2d(2, stride=2),\n",
    "        nn.Conv2d(32, 64, kernel_size=3),\n",
    "        nn.Dropout(0.25),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(9216, 128),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(128, 10 if only_digits else 62),\n",
    "        nn.ReLU()\n",
    "        ).to(device)\n",
    "        '''\n",
    "        self.optimizer = torch.optim.Adam(self.network.parameters())\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "        self.node_id = node_id\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        losses = []\n",
    "        for idx, (data_x, data_y) in enumerate(self.train_dataloader):\n",
    "            #print(\"data_x\", data_x.shape)\n",
    "            #print(\"data_y\", data_y.shape)\n",
    "            #plt.imshow(data_x[1][0])\n",
    "            output = self.network(data_x.to(device))\n",
    "            self.optimizer.zero_grad()\n",
    "            #print(output.shape)\n",
    "            #print(data_y)\n",
    "            data_y = target_transform(data_y)\n",
    "            \n",
    "            #loss = nn.functional.mse_loss(output, data_y.to(device))\n",
    "            loss = self.criterion(output, data_y.to(device))\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        return sum(losses)/len(losses)\n",
    "    \n",
    "    def testing(self):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # test_running_loss = 0.0\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        test_accuracy = []\n",
    "        test_running_losses = []\n",
    "        for idx, (data_x, data_y) in enumerate(self.test_dataloader):\n",
    "            output = self.network(data_x.to(device))\n",
    "            \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            data_y = data_y.to(predicted.device)\n",
    "            total += data_y.size(0)\n",
    "            correct += (predicted == data_y).sum().item()\n",
    "            \n",
    "            loss = self.criterion(output, data_y)\n",
    "            predictions.append(predicted.cpu())\n",
    "            labels.append(data_y.cpu())\n",
    "            \n",
    "            test_running_losses.append(loss.item())\n",
    "            print('Epoch %d test loss: %.3f' % (idx + 1, test_running_losses[-1]))\n",
    "            #print(test_running_losses)\n",
    "            #test_running_loss += loss.item()\n",
    "            #test_loss.append(test_running_loss / len(self.test_dataloader))\n",
    "            test_accuracy.append(100 * correct / total)\n",
    "        \n",
    "        #print(predictions)\n",
    "        predictions = np.concatenate(predictions)\n",
    "        labels = np.concatenate(labels)\n",
    "        self.f1_score= f1_score(labels, predictions, average=\"weighted\")\n",
    "        self.test_accuracy = test_accuracy[-1]\n",
    "        #print(self.test_accuracy)\n",
    "        self.test_loss =  sum(test_running_losses)/len(test_running_losses)\n",
    "        #print(\"test loss \",self.test_loss)\n",
    "       \n",
    "    \n",
    "    def share_x_ij(self):\n",
    "        x = self.network.state_dict()\n",
    "        r = torch.randint(0, 5, [num_nodes])\n",
    "        s_r = torch.sum(r)\n",
    "        j=self.node_id\n",
    "        for i in range(num_nodes):\n",
    "            x_i_j[(i,j)]={}\n",
    "            for key in x.keys():\n",
    "                x_i_j[(i,j)][key]=x[key]*r[i]/s_r\n",
    "    \n",
    "    def share_s_i(self):\n",
    "        i = self.node_id\n",
    "        s_i[i] = {}\n",
    "        for key in x_i_j[(0,0)].keys():\n",
    "            s_i[i][key] = sum([x_i_j[(i,j)][key] for j in range(num_nodes)])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size  343\n",
      "Mean size  torch.Size([1, 28, 28])\n",
      "Standard deviation size  torch.Size([1, 28, 28])\n",
      "Dataset size  372\n",
      "Mean size  torch.Size([1, 28, 28])\n",
      "Standard deviation size  torch.Size([1, 28, 28])\n",
      "Dataset size  364\n",
      "Mean size  torch.Size([1, 28, 28])\n",
      "Standard deviation size  torch.Size([1, 28, 28])\n",
      "Dataset size  358\n",
      "Mean size  torch.Size([1, 28, 28])\n",
      "Standard deviation size  torch.Size([1, 28, 28])\n",
      "Dataset size  284\n",
      "Mean size  torch.Size([1, 28, 28])\n",
      "Standard deviation size  torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "#for i, loader_data in enumerate(zip(*loader)):\n",
    "#    train_loaders, test_loaders = loader_data\n",
    "\n",
    "nodes = []\n",
    "for i in range(num_nodes):\n",
    "    nodes.append(FederatedNode(train_loaders[i], test_loaders[i], i)) \n",
    "\n",
    "#nodes = [FederatedNode(l, i) for i,l in enumerate())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ankit\\AppData\\Local\\Temp\\ipykernel_13260\\2074874273.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target_transform = lambda x: torch.nn.functional.one_hot(torch.tensor(x),num_class).float()\n",
      "100%|██████████| 1/1 [00:00<00:00, 16.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by FL with SMPC 0.06409287452697754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "#with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "#    with record_function(\"model_training\"):\n",
    "\n",
    "start_time = time.time()\n",
    "for i in tqdm(range(epoch_total)):\n",
    "    epoch_losses = []\n",
    "    for node in nodes:\n",
    "        loss = node.train_epoch()\n",
    "        epoch_losses.append(loss)\n",
    "    losses.append(epoch_losses)\n",
    "\n",
    "    x_i_j = {}\n",
    "    s_i = {}\n",
    "    for node in nodes:\n",
    "        node.share_x_ij()\n",
    "    \n",
    "    for node in nodes:\n",
    "        node.share_s_i()\n",
    "    \n",
    "    #av_state = {}\n",
    "    #print(s_i[0])\n",
    "    #for key in s_i[0].keys():\n",
    "    #    av_state[key]=torch.mean(torch.tensor([s_i[i][key] for i in s_i]), dim=[0])\n",
    "    averaged_state = {}\n",
    "    for key in s_i[0].keys():\n",
    "        param_value = 0\n",
    "        for i in s_i:\n",
    "            param_value += s_i[i][key]\n",
    "        \n",
    "        averaged_state[key] = param_value/num_nodes\n",
    "\n",
    "    for node in nodes:\n",
    "        node.network.load_state_dict(averaged_state)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # states = [i.network.state_dict() for i in nodes]\n",
    "    # av_state = {}\n",
    "    # for key in states[0]:\n",
    "    #     av_state[key] = sum([s[key] for s in states])/num_nodes\n",
    "    # for node in nodes:\n",
    "    #     node.network.load_state_dict(av_state)\n",
    "\n",
    "time_FL_SMPC = time.time() - start_time\n",
    "\n",
    "print(\"Time taken by FL with SMPC\", time_FL_SMPC)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ed074e74c0>,\n",
       " <matplotlib.lines.Line2D at 0x2ed074e6440>,\n",
       " <matplotlib.lines.Line2D at 0x2ed074e7e20>,\n",
       " <matplotlib.lines.Line2D at 0x2ed074e6d40>,\n",
       " <matplotlib.lines.Line2D at 0x2ed074e66b0>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Node  0\n",
      "Epoch 1 test loss: 4.109\n",
      "Node Test Accuracy 15.384615384615385\n",
      "Node Test loss 4.108736991882324\n",
      "Node F1_Score  0.04102564102564103\n",
      "\n",
      "Node  1\n",
      "Epoch 1 test loss: 4.120\n",
      "Node Test Accuracy 7.142857142857143\n",
      "Node Test loss 4.120253086090088\n",
      "Node F1_Score  0.009523809523809525\n",
      "\n",
      "Node  2\n",
      "Epoch 1 test loss: 4.120\n",
      "Node Test Accuracy 9.75609756097561\n",
      "Node Test loss 4.12024450302124\n",
      "Node F1_Score  0.017344173441734414\n",
      "\n",
      "Node  3\n",
      "Epoch 1 test loss: 4.122\n",
      "Node Test Accuracy 5.0\n",
      "Node Test loss 4.1216654777526855\n",
      "Node F1_Score  0.0047619047619047615\n",
      "\n",
      "Node  4\n",
      "Epoch 1 test loss: 4.120\n",
      "Node Test Accuracy 6.25\n",
      "Node Test loss 4.119555950164795\n",
      "Node F1_Score  0.007352941176470588\n"
     ]
    }
   ],
   "source": [
    "#nodes = [FederatedNode(l, i) for i,l in enumerate(test_loaders)]\n",
    "\n",
    "test_losses = []\n",
    "with torch.no_grad():\n",
    "    for i, node in enumerate(nodes):\n",
    "        print()\n",
    "        print(\"Node \", i)\n",
    "        node.testing()\n",
    "        #test_losses.append(node.test_loss)\n",
    "        print(\"Node Test Accuracy\", node.test_accuracy)\n",
    "        print(\"Node Test loss\", node.test_loss)\n",
    "        print(\"Node F1_Score \", node.f1_score)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size  343\n",
      "Mean size  torch.Size([1, 28, 28])\n",
      "Standard deviation size  torch.Size([1, 28, 28])\n",
      "Dataset size  372\n",
      "Mean size  torch.Size([1, 28, 28])\n",
      "Standard deviation size  torch.Size([1, 28, 28])\n",
      "Dataset size  364\n",
      "Mean size  torch.Size([1, 28, 28])\n",
      "Standard deviation size  torch.Size([1, 28, 28])\n",
      "Dataset size  358\n",
      "Mean size  torch.Size([1, 28, 28])\n",
      "Standard deviation size  torch.Size([1, 28, 28])\n",
      "Dataset size  284\n",
      "Mean size  torch.Size([1, 28, 28])\n",
      "Standard deviation size  torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "#for i, loader_data in enumerate(zip(*loader)):\n",
    "#    train_loaders, test_loaders = loader_data\n",
    "\n",
    "nodes = []\n",
    "for i in range(num_nodes):\n",
    "    nodes.append(FederatedNode(train_loaders[i], test_loaders[i], i)) \n",
    "\n",
    "#nodes = [FederatedNode(l, i) for i,l in enumerate())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]C:\\Users\\ankit\\AppData\\Local\\Temp\\ipykernel_13260\\2074874273.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target_transform = lambda x: torch.nn.functional.one_hot(torch.tensor(x),num_class).float()\n",
      "100%|██████████| 5/5 [00:00<00:00, 21.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by FL without SMPC 0.2345585823059082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for i in tqdm(range(5)):\n",
    "    epoch_losses = []\n",
    "    \n",
    "    for node in nodes:\n",
    "        loss = node.train_epoch()\n",
    "        epoch_losses.append(loss)\n",
    "    losses.append(epoch_losses)\n",
    "\n",
    "\n",
    "    \n",
    "    av_state = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    states = [i.network.state_dict() for i in nodes]\n",
    "    av_state = {}\n",
    "    for key in states[0]:\n",
    "        av_state[key] = sum([s[key] for s in states])/num_nodes\n",
    "    for node in nodes:\n",
    "        node.network.load_state_dict(av_state)\n",
    "\n",
    "time_FL = time.time() - start_time\n",
    "\n",
    "print(\"Time taken by FL without SMPC\", time_FL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Node  0\n",
      "Epoch 1 test loss: 4.123\n",
      "Node Test Accuracy 0.0\n",
      "Node Test loss 4.122610569000244\n",
      "Node F1_Score  0.0\n",
      "\n",
      "Node  1\n",
      "Epoch 1 test loss: 4.107\n",
      "Node Test Accuracy 2.380952380952381\n",
      "Node Test loss 4.107358455657959\n",
      "Node F1_Score  0.0012210012210012208\n",
      "\n",
      "Node  2\n",
      "Epoch 1 test loss: 4.119\n",
      "Node Test Accuracy 0.0\n",
      "Node Test loss 4.118530750274658\n",
      "Node F1_Score  0.0\n",
      "\n",
      "Node  3\n",
      "Epoch 1 test loss: 4.122\n",
      "Node Test Accuracy 5.0\n",
      "Node Test loss 4.122112274169922\n",
      "Node F1_Score  0.0064516129032258064\n",
      "\n",
      "Node  4\n",
      "Epoch 1 test loss: 4.133\n",
      "Node Test Accuracy 3.125\n",
      "Node Test loss 4.1330413818359375\n",
      "Node F1_Score  0.0027173913043478264\n"
     ]
    }
   ],
   "source": [
    "#nodes = [FederatedNode(l, i) for i,l in enumerate(test_loaders)]\n",
    "\n",
    "test_losses = []\n",
    "with torch.no_grad():\n",
    "    for i, node in enumerate(nodes):\n",
    "        #print()\n",
    "        #print(\"Node \", i)\n",
    "        node.testing()\n",
    "        #test_losses.append(node.test_loss)\n",
    "        # print(\"Node Test Accuracy\", node.test_accuracy)\n",
    "        # print(\"Node Test loss\", node.test_loss)\n",
    "        # print(\"Node F1_Score \", node.f1_score)\n",
    "\n",
    "print(\"Done\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Mean torch.Size([1, 28, 28])\n",
      "Global std  torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "global_mean = 0.0\n",
    "global_std = 0.0\n",
    "eqn1= 0.0 \n",
    "eqn2 = 0.0\n",
    "eqn3 = 0.0\n",
    "for node in nodes:\n",
    "    eqn1 += node.mean * node.dataset_size\n",
    "    eqn2 += node.dataset_size \n",
    "    eqn3 += node.std\n",
    "\n",
    "\n",
    "global_mean = eqn1/eqn2\n",
    "global_std = eqn3/eqn2\n",
    "print(\"Global Mean\", global_mean.shape)\n",
    "print(\"Global std \", global_std.shape)\n",
    "#plt.imshow(global_mean.squeeze())\n",
    "#plt.imshow(global_std.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
