{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.utils.data\n",
    "from torch import nn\n",
    "import torchvision, torchvision.datasets\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "\n",
    "from fedlab.main.fedlab_benchmarks.leaf.dataloader import get_LEAF_dataloader\n",
    "\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import time\n",
    "from sklearn.metrics import f1_score   \n",
    "import numpy as np\n",
    "    \n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu117\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_femnist_shakespeare_dataset(**args):\n",
    "    if args['dataset'] == 'femnist' or args['dataset'] == 'shakespeare':\n",
    "        trainloader, testloader = get_LEAF_dataloader(dataset=args['dataset'],\n",
    "                                                      client_id=args['rank'])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset:\", args['dataset'])\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x00000271DCC60E80>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x00000271DCE093C0>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x00000271DCE089A0>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x00000271DCE0B6D0>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x00000271DCE09000>\n"
     ]
    }
   ],
   "source": [
    "train_loaders = []\n",
    "test_loaders = []\n",
    "num_nodes = 5\n",
    "\n",
    "for i in range(num_nodes):\n",
    "    args = {'dataset': 'femnist', 'rank': i}\n",
    "    trainloader, testloader = get_femnist_shakespeare_dataset(**args)\n",
    "    train_loaders.append(trainloader)\n",
    "    test_loaders.append(testloader)\n",
    "\n",
    "#loader = zip(train_loaders, test_loaders)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "[<torch.utils.data.dataloader.DataLoader object at 0x00000271DCC609D0>, <torch.utils.data.dataloader.DataLoader object at 0x00000271DCE0B430>, <torch.utils.data.dataloader.DataLoader object at 0x00000271DCE0A5C0>, <torch.utils.data.dataloader.DataLoader object at 0x00000271DCE0A110>, <torch.utils.data.dataloader.DataLoader object at 0x00000271DCE09060>]\n",
      "343\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loaders))\n",
    "print(len(test_loaders))\n",
    "print(test_loaders)\n",
    "print(len(train_loaders[0].dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3070 Ti Laptop GPU'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "torch.cuda.get_device_name(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "target_transform = lambda x: torch.nn.functional.one_hot(torch.tensor(x),62).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_dataset(dataset, n):\n",
    "#     torch.utils.data.random_split(dataset, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Inital MNIST\\ntrain_datasets = torch.utils.data.random_split(torchvision.datasets.MNIST('datasets/',\\n                                                                           download=True, train=True, transform=transform, target_transform=target_transform), [1/num_nodes]*num_nodes)\\ntrain_loaders = [torch.utils.data.DataLoader(i, batch_size=1000000, num_workers=0) for i in train_datasets]\\n\""
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_dataset2 = torchvision.datasets.MNIST('datasets/', download=True, train=True, transform=transform, target_transform=target_transform),\n",
    "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1000000, num_workers=0)\n",
    "\n",
    "# test_dataset = torchvision.datasets.MNIST('datasets/', download=True, train=False, transform=transform, target_transform=target_transform)\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000000, num_workers=0)\n",
    "\n",
    "'''\n",
    "# Inital MNIST\n",
    "train_datasets = torch.utils.data.random_split(torchvision.datasets.MNIST('datasets/',\n",
    "                                                                           download=True, train=True, transform=transform, target_transform=target_transform), [1/num_nodes]*num_nodes)\n",
    "train_loaders = [torch.utils.data.DataLoader(i, batch_size=1000000, num_workers=0) for i in train_datasets]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_i_j = {}\n",
    "s_i = {}\n",
    "w_k = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FederatedNode:\n",
    "    def __init__(self, train_dataloader, test_dataloader, node_id) -> None:\n",
    "        self.dataset_size = len(train_dataloader.dataset)\n",
    "        channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "        for data, _ in train_dataloader:\n",
    "            # Mean over batch, height and width, but not over the channels\n",
    "            channels_sum += torch.mean(data, dim=[0])\n",
    "            channels_squared_sum += torch.mean(data**2, dim=[0])\n",
    "            num_batches += 1\n",
    "    \n",
    "        self.mean = channels_sum / num_batches\n",
    "        self.test_loss = 0.0\n",
    "        self.test_accuracy = 0.0\n",
    "        self.train_accuracy = 0.0\n",
    "        self.f1_score = 0.0\n",
    "\n",
    "\n",
    "        # std = sqrt(E[X^2] - (E[X])^2)\n",
    "        self.std = (channels_squared_sum / num_batches - self.mean ** 2) ** 0.5\n",
    "        print(\"Dataset size \", self.dataset_size)\n",
    "        print(\"Mean size \", self.mean.shape)\n",
    "        print(\"Standard deviation size \", self.std.shape)\n",
    "        \n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(784,56),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(56, 62)\n",
    "        ).to(device)\n",
    "\n",
    "        '''\n",
    "        only_digits=False\n",
    "        self.network = nn.Sequential(\n",
    "        nn.Conv2d(1, 32, kernel_size=3),\n",
    "        nn.MaxPool2d(2, stride=2),\n",
    "        nn.Conv2d(32, 64, kernel_size=3),\n",
    "        nn.Dropout(0.25),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(9216, 128),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(128, 10 if only_digits else 62),\n",
    "        nn.ReLU()\n",
    "        ).to(device)\n",
    "        '''\n",
    "        self.optimizer = torch.optim.Adam(self.network.parameters())\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "        self.node_id = node_id\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        losses = []\n",
    "        for idx, (data_x, data_y) in enumerate(self.train_dataloader):\n",
    "            #print(\"data_x\", data_x.shape)\n",
    "            #print(\"data_y\", data_y.shape)\n",
    "            #plt.imshow(data_x[1][0])\n",
    "            output = self.network(data_x.to(device))\n",
    "            self.optimizer.zero_grad()\n",
    "            #print(output.shape)\n",
    "            #print(data_y)\n",
    "            data_y = target_transform(data_y)\n",
    "            \n",
    "            loss = nn.functional.mse_loss(output, data_y.to(device))\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        return sum(losses)/len(losses)\n",
    "    \n",
    "    def testing(self):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # test_running_loss = 0.0\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        test_accuracy = []\n",
    "        test_running_losses = []\n",
    "        for idx, (data_x, data_y) in enumerate(self.test_dataloader):\n",
    "            output = self.network(data_x.to(device))\n",
    "            \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            data_y = data_y.to(predicted.device)\n",
    "            total += data_y.size(0)\n",
    "            correct += (predicted == data_y).sum().item()\n",
    "            \n",
    "            loss = self.criterion(output, data_y)\n",
    "            predictions.append(predicted.cpu())\n",
    "            labels.append(data_y.cpu())\n",
    "            \n",
    "            test_running_losses.append(loss.item())\n",
    "            #print('Epoch %d test loss: %.3f' % (idx + 1, test_running_losses[-1]))\n",
    "            #print(test_running_losses)\n",
    "            #test_running_loss += loss.item()\n",
    "            #test_loss.append(test_running_loss / len(self.test_dataloader))\n",
    "            test_accuracy.append(100 * correct / total)\n",
    "        \n",
    "        #print(predictions)\n",
    "        predictions = np.concatenate(predictions)\n",
    "        labels = np.concatenate(labels)\n",
    "        self.f1_score= f1_score(labels, predictions, average=\"weighted\")\n",
    "        self.test_accuracy = test_accuracy[-1]\n",
    "        #print(self.test_accuracy)\n",
    "        self.test_loss =  sum(test_running_losses)/len(test_running_losses)\n",
    "        #print(\"test loss \",self.test_loss)\n",
    "       \n",
    "    def share_x_ij(self):\n",
    "        x = self.network.state_dict()\n",
    "        r = torch.randint(1, 5, [num_nodes])\n",
    "        s_r = torch.sum(r)\n",
    "        j=self.node_id\n",
    "        for i in range(num_nodes):\n",
    "            x_i_j[(i,j)]={}\n",
    "            for key in x.keys():\n",
    "                x_i_j[(i,j)][key]=x[key]*r[i]/s_r\n",
    "                \n",
    "        \n",
    "    \n",
    "    def share_s_i(self):\n",
    "        i = self.node_id\n",
    "        s_i[i] = {}\n",
    "        for key in x_i_j[(0,0)].keys():\n",
    "            s_i[i][key] = sum([x_i_j[(i,j)][key] for j in range(num_nodes)])\n",
    "\n",
    "    def share_x_ij_neighbours(self, neighbour_nodes):\n",
    "        j=self.node_id\n",
    "        num_neighbour_nodes = len(neighbour_nodes)\n",
    "        x = self.network.state_dict()\n",
    "        r = torch.randint(1, 5, [num_neighbour_nodes])\n",
    "        s_r = torch.sum(r)\n",
    "        \n",
    "        for i, n in enumerate(neighbour_nodes):\n",
    "            x_i_j[(n,j)]={}\n",
    "            for key in x.keys():\n",
    "                x_i_j[(n,j)][key]=x[key]*r[i]/s_r*self.dataset_size\n",
    "\n",
    "    def share_s_i_neighbours(self, neighbour_nodes):\n",
    "        i = self.node_id\n",
    "        s_i[i] = {}\n",
    "        \n",
    "        for key in x_i_j[list(x_i_j.keys())[0]].keys():\n",
    "            s_i[i][key] = sum([x_i_j[(i,j)][key] for j in neighbour_nodes])\n",
    "\n",
    "\n",
    "    def share_FedavgP2P(self, nodes):\n",
    "        dataset_size_all = [n.dataset_size for n in nodes]\n",
    "        i = self.node_id\n",
    "        C = 0.5\n",
    "        A = num_nodes - 1\n",
    "        m = C*A\n",
    "        #n_k = self.dataset_size\n",
    "\n",
    "        # Random clients\n",
    "        S_t = random.sample([ j for j in range(num_nodes) if j!=i], int(m)) \n",
    "        S_t.append(self.node_id)\n",
    "        #print(\"Clients \",S_t)\n",
    "        #S_t = random.sample(list(range(num_nodes)) , int(m))\n",
    "        #print(\"n_k \",n_k)\n",
    "        #print(\"m neighbors\", m)\n",
    "        #print(\"S_t\", S_t)\n",
    "        w_c = self.network.state_dict()\n",
    "        n_c = self.dataset_size\n",
    "        n_t = n_c\n",
    "        for s in S_t:\n",
    "            n_t += dataset_size_all[s]\n",
    "        \n",
    "        for j in S_t: \n",
    "            nodes[j].share_x_ij_neighbours(S_t)\n",
    "        for j in S_t: \n",
    "            nodes[j].share_s_i_neighbours(S_t)\n",
    "                \n",
    "        for key in nodes[0].network.state_dict():\n",
    "            w_c[key] = w_c[key]*n_c/n_t\n",
    "\n",
    "            for j in S_t: \n",
    "                n_k = dataset_size_all[j]\n",
    "                #states = nodes[j].network.state_dict()\n",
    "                averaged_state = {}\n",
    "            \n",
    "                for key in s_i[list(s_i.keys())[0]].keys():\n",
    "                    param_value = 0\n",
    "                    for i in s_i:\n",
    "                        param_value += s_i[i][key]\n",
    "                    \n",
    "                    averaged_state[key] = param_value/len(S_t)/n_t\n",
    "                #print(averaged_state)\n",
    "                #contributed_state = n_k/n_t*averaged_state[key]\n",
    "                #w_c[key] = w_c[key] + contributed_state\n",
    "                \n",
    "        self.network.load_state_dict(w_c)\n",
    "           \n",
    "\n",
    "        # for key in x_i_j[(0,0)].keys():\n",
    "        #     for j in S_t:      \n",
    "        #         n_k = dataset_size_all[j]\n",
    "        #         contributed_weight = n_k/n_t*x_i_j[(i, j)][key]\n",
    "        #         w_k[i][key] = w_k[i].setdefault(key, 0) + contributed_weight\n",
    "                \n",
    "\n",
    "                #w_k[i][key] = sum( * [x_i_j[(i, j)][key] for j in S_t])\n",
    "            \n",
    "        #print(w_k)\n",
    "\n",
    "        #print(\"Total dataset samples n_t\", n_t)    \n",
    "        \n",
    "    def preprocessFedavg(self, dataset_size_all, nodes):\n",
    "        i = self.node_id\n",
    "        C = 0.5\n",
    "        A = num_nodes - 1\n",
    "        m = C*A\n",
    "        #n_k = self.dataset_size\n",
    "\n",
    "        # Random clients\n",
    "        S_t = random.sample([ j for j in range(num_nodes) if j!=i], int(m)) \n",
    "        S_t.append(self.node_id)\n",
    "        #print(\"Clients \",S_t)\n",
    "\n",
    "        w_c = self.network.state_dict()\n",
    "        n_c = self.dataset_size\n",
    "        n_t = n_c\n",
    "        for s in S_t:\n",
    "            n_t += dataset_size_all[s]\n",
    "        \n",
    "        return S_t\n",
    "                \n",
    "\n",
    "              \n",
    "             \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size  343\n",
      "Mean size  torch.Size([1, 28, 28])\n",
      "Standard deviation size  torch.Size([1, 28, 28])\n",
      "Dataset size  372\n",
      "Mean size  torch.Size([1, 28, 28])\n",
      "Standard deviation size  torch.Size([1, 28, 28])\n",
      "Dataset size  364\n",
      "Mean size  torch.Size([1, 28, 28])\n",
      "Standard deviation size  torch.Size([1, 28, 28])\n",
      "Dataset size  358\n",
      "Mean size  torch.Size([1, 28, 28])\n",
      "Standard deviation size  torch.Size([1, 28, 28])\n",
      "Dataset size  284\n",
      "Mean size  torch.Size([1, 28, 28])\n",
      "Standard deviation size  torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "#for i, loader_data in enumerate(zip(*loader)):\n",
    "#    train_loaders, test_loaders = loader_data\n",
    "\n",
    "nodes = []\n",
    "for i in range(num_nodes):\n",
    "    nodes.append(FederatedNode(train_loaders[i], test_loaders[i], i)) \n",
    "\n",
    "#nodes = [FederatedNode(l, i) for i,l in enumerate())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]C:\\Users\\ankit\\AppData\\Local\\Temp\\ipykernel_20060\\3311650527.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target_transform = lambda x: torch.nn.functional.one_hot(torch.tensor(x),62).float()\n",
      "100%|██████████| 250/250 [00:03<00:00, 63.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by FL with SMPC 3.9382474422454834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "losses = {}\n",
    "#with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "#    with record_function(\"model_training\"):\n",
    "\n",
    "start_time = time.time()\n",
    "start_time = time.time()\n",
    "dataset_size_all = {}\n",
    "epochs ={i:0 for i in range(num_nodes)}\n",
    "epoch_total = 50\n",
    "for i in tqdm(range(epoch_total*num_nodes)):\n",
    "    cands = [i for i in epochs if epochs[i]<epoch_total]\n",
    "    node = nodes[cands[torch.randint(len(cands), (1,)).item()]]\n",
    "    del cands\n",
    "    loss = node.train_epoch()\n",
    "    node.share_FedavgP2P(nodes)\n",
    "    \n",
    "    epochs[node.node_id] += 1\n",
    "    losses[(node.node_id, epochs[node.node_id])]=loss\n",
    "    # x_i_j = {}\n",
    "    # s_i = {}\n",
    "    # for node in nodes:\n",
    "    #     node.share_x_ij()\n",
    "    \n",
    "    # for node in nodes:\n",
    "    #     node.share_s_i()\n",
    "    \n",
    "    # FedavgP2P\n",
    "\n",
    "\n",
    "    #states = [i.network.state_dict() for i in nodes]\n",
    "    \n",
    "    # av_state = {}\n",
    "    \n",
    "    # for key in states[0]:\n",
    "    #     av_state[key] = sum([s[key] for s in states])/num_nodes\n",
    "        \n",
    "        \n",
    "      \n",
    "    #av_state = {}\n",
    "    #print(s_i[0])\n",
    "    #for key in s_i[0].keys():\n",
    "    #    av_state[key]=torch.mean(torch.tensor([s_i[i][key] for i in s_i]), dim=[0])\n",
    "\n",
    "'''\n",
    " # Averaging weights after SMPC logic   \n",
    "    averaged_state = {}\n",
    "    for key in s_i[0].keys():\n",
    "        param_value = 0\n",
    "        for i in s_i:\n",
    "            param_value += s_i[i][key]\n",
    "        \n",
    "        averaged_state[key] = param_value/num_nodes\n",
    "\n",
    "    for node in nodes:\n",
    "        node.network.load_state_dict(averaged_state)\n",
    "\n",
    "'''\n",
    "    \n",
    "    \n",
    "    # states = [i.network.state_dict() for i in nodes]\n",
    "    # av_state = {}\n",
    "    # for key in states[0]:\n",
    "    #     av_state[key] = sum([s[key] for s in states])/num_nodes\n",
    "    # for node in nodes:\n",
    "    #     node.network.load_state_dict(av_state)\n",
    "\n",
    "time_FL_SMPC = time.time() - start_time\n",
    "\n",
    "print(\"Time taken by FL with SMPC\", time_FL_SMPC)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 1): 0.07353825867176056,\n",
       " (3, 1): 0.06238468115528425,\n",
       " (4, 1): 0.04898064645628134,\n",
       " (2, 1): 0.04796862415969372,\n",
       " (2, 2): 0.016456063836812973,\n",
       " (3, 2): 0.016480324789881706,\n",
       " (1, 2): 0.016471896320581436,\n",
       " (1, 3): 0.016134091342488926,\n",
       " (1, 4): 0.01611370158692201,\n",
       " (3, 3): 0.01613425773878892,\n",
       " (0, 1): 0.047261593863368034,\n",
       " (4, 2): 0.016511892278989155,\n",
       " (0, 2): 0.01646471892793973,\n",
       " (4, 3): 0.016149551918109257,\n",
       " (0, 3): 0.016124846413731575,\n",
       " (4, 4): 0.01611912250518799,\n",
       " (2, 3): 0.01613809789220492,\n",
       " (3, 4): 0.016115390385190647,\n",
       " (4, 5): 0.01611354077855746,\n",
       " (2, 4): 0.01611182528237502,\n",
       " (1, 5): 0.01611176257332166,\n",
       " (4, 6): 0.01611120191713174,\n",
       " (4, 7): 0.016109831631183624,\n",
       " (0, 4): 0.016089300935467083,\n",
       " (3, 5): 0.016113239650925,\n",
       " (3, 6): 0.016110874091585476,\n",
       " (3, 7): 0.016109076639016468,\n",
       " (4, 8): 0.016108769923448563,\n",
       " (4, 9): 0.016108093162377674,\n",
       " (1, 6): 0.016110006719827652,\n",
       " (1, 7): 0.016108502944310505,\n",
       " (4, 10): 0.01610735182960828,\n",
       " (2, 5): 0.016106193885207176,\n",
       " (1, 8): 0.01610778955121835,\n",
       " (1, 9): 0.016106045494476955,\n",
       " (0, 5): 0.01607208512723446,\n",
       " (2, 6): 0.016103843227028847,\n",
       " (2, 7): 0.01610296592116356,\n",
       " (3, 8): 0.016107644885778427,\n",
       " (3, 9): 0.016107162460684776,\n",
       " (0, 6): 0.016055598855018616,\n",
       " (4, 11): 0.016106837739547093,\n",
       " (1, 10): 0.016105089336633682,\n",
       " (2, 8): 0.016101155430078506,\n",
       " (3, 10): 0.016106438512603443,\n",
       " (3, 11): 0.016105061396956444,\n",
       " (2, 9): 0.016100449487566948,\n",
       " (2, 10): 0.016100599740942318,\n",
       " (1, 11): 0.016104913627107937,\n",
       " (3, 12): 0.01610425425072511,\n",
       " (4, 12): 0.01610609454413255,\n",
       " (2, 11): 0.016100230316321056,\n",
       " (4, 13): 0.01610553450882435,\n",
       " (0, 7): 0.01604357734322548,\n",
       " (4, 14): 0.01610504773755868,\n",
       " (1, 12): 0.016103666896621387,\n",
       " (1, 13): 0.016103433445096016,\n",
       " (4, 15): 0.016104744126399357,\n",
       " (3, 13): 0.016103491187095642,\n",
       " (2, 12): 0.016098794216911,\n",
       " (0, 8): 0.01603916970392068,\n",
       " (4, 16): 0.016104223827521007,\n",
       " (3, 14): 0.016103729605674744,\n",
       " (4, 17): 0.016103758787115414,\n",
       " (1, 14): 0.016102366770307224,\n",
       " (1, 15): 0.016102229555447895,\n",
       " (4, 18): 0.01610366255044937,\n",
       " (3, 15): 0.01610312486688296,\n",
       " (0, 9): 0.016034527371327083,\n",
       " (1, 16): 0.016101224347949028,\n",
       " (3, 16): 0.01610178065796693,\n",
       " (1, 17): 0.016101305683453877,\n",
       " (3, 17): 0.01610223886867364,\n",
       " (1, 18): 0.01610095240175724,\n",
       " (1, 19): 0.016100631405909855,\n",
       " (0, 10): 0.016025815159082413,\n",
       " (2, 13): 0.016099095965425175,\n",
       " (0, 11): 0.01602170802652836,\n",
       " (2, 14): 0.016098707914352417,\n",
       " (3, 18): 0.0161011287321647,\n",
       " (4, 19): 0.016103238488237064,\n",
       " (3, 19): 0.016101187095046043,\n",
       " (2, 15): 0.01609833352267742,\n",
       " (2, 16): 0.01609798272450765,\n",
       " (4, 20): 0.016102822497487068,\n",
       " (3, 20): 0.016101228073239326,\n",
       " (2, 17): 0.01609782377878825,\n",
       " (0, 12): 0.01602391277750333,\n",
       " (4, 21): 0.01610265051325162,\n",
       " (2, 18): 0.016096683219075203,\n",
       " (3, 21): 0.01610098034143448,\n",
       " (0, 13): 0.01601955605049928,\n",
       " (3, 22): 0.016100674246748287,\n",
       " (0, 14): 0.016021714235345524,\n",
       " (4, 22): 0.016102325171232224,\n",
       " (0, 15): 0.016018298144141834,\n",
       " (2, 19): 0.016096895560622215,\n",
       " (4, 23): 0.0161019004881382,\n",
       " (0, 16): 0.016021158546209335,\n",
       " (3, 23): 0.01609940081834793,\n",
       " (1, 20): 0.016100209206342697,\n",
       " (2, 20): 0.016095848754048347,\n",
       " (1, 21): 0.016099905595183372,\n",
       " (0, 17): 0.016022102286418278,\n",
       " (0, 18): 0.016017965972423553,\n",
       " (0, 19): 0.016022140781084698,\n",
       " (3, 24): 0.01609984040260315,\n",
       " (1, 22): 0.016099516302347183,\n",
       " (0, 20): 0.016023181999723118,\n",
       " (3, 25): 0.01609973857800166,\n",
       " (2, 21): 0.01609630323946476,\n",
       " (4, 24): 0.016101909801363945,\n",
       " (4, 25): 0.016101722915967304,\n",
       " (2, 22): 0.016095322867234547,\n",
       " (0, 21): 0.016019633660713833,\n",
       " (4, 26): 0.01610119951268037,\n",
       " (2, 23): 0.01609582578142484,\n",
       " (3, 26): 0.016099287196993828,\n",
       " (2, 24): 0.016094659144679706,\n",
       " (2, 25): 0.01609458898504575,\n",
       " (4, 27): 0.016100910181800526,\n",
       " (2, 26): 0.01609536757071813,\n",
       " (1, 23): 0.016098512336611748,\n",
       " (0, 22): 0.01602316585679849,\n",
       " (2, 27): 0.016094292824467022,\n",
       " (1, 24): 0.016097840542594593,\n",
       " (3, 27): 0.01609921207030614,\n",
       " (3, 28): 0.01609901028374831,\n",
       " (1, 25): 0.016098394989967346,\n",
       " (1, 26): 0.016097574805219967,\n",
       " (0, 23): 0.016019873321056366,\n",
       " (3, 29): 0.016098552693923313,\n",
       " (2, 28): 0.0160936638712883,\n",
       " (3, 30): 0.016097474843263626,\n",
       " (3, 31): 0.016097843026121456,\n",
       " (0, 24): 0.0160237904638052,\n",
       " (3, 32): 0.016098016873002052,\n",
       " (2, 29): 0.016094734892249107,\n",
       " (1, 27): 0.01609793243308862,\n",
       " (3, 33): 0.01609696199496587,\n",
       " (3, 34): 0.016096441075205803,\n",
       " (1, 28): 0.01609800507624944,\n",
       " (2, 30): 0.01609487272799015,\n",
       " (0, 25): 0.01602596106628577,\n",
       " (1, 29): 0.016096976896127064,\n",
       " (1, 30): 0.016097243254383404,\n",
       " (4, 28): 0.01610068293909232,\n",
       " (4, 29): 0.016100474322835606,\n",
       " (1, 31): 0.016097145155072212,\n",
       " (2, 31): 0.016093431661526363,\n",
       " (3, 35): 0.016095889111359913,\n",
       " (0, 26): 0.01602703022460143,\n",
       " (3, 36): 0.01609599528213342,\n",
       " (0, 27): 0.01602780446410179,\n",
       " (2, 32): 0.016093942647178967,\n",
       " (3, 37): 0.016096627960602444,\n",
       " (4, 30): 0.016100590427716572,\n",
       " (2, 33): 0.016094326972961426,\n",
       " (2, 34): 0.016093943888942402,\n",
       " (3, 38): 0.016096560284495354,\n",
       " (4, 31): 0.016100533306598663,\n",
       " (0, 28): 0.016023656353354454,\n",
       " (4, 32): 0.016100314756234486,\n",
       " (1, 32): 0.016096959511439007,\n",
       " (2, 35): 0.01609294426937898,\n",
       " (2, 36): 0.016093389441569645,\n",
       " (0, 29): 0.016023047268390656,\n",
       " (1, 33): 0.016096688186128933,\n",
       " (3, 39): 0.016096757724881172,\n",
       " (0, 30): 0.016022053236762684,\n",
       " (0, 31): 0.01602700538933277,\n",
       " (3, 40): 0.01609570098419984,\n",
       " (2, 37): 0.016093404963612556,\n",
       " (4, 33): 0.01609981432557106,\n",
       " (4, 34): 0.016099572802583378,\n",
       " (3, 41): 0.01609630820651849,\n",
       " (3, 42): 0.016094962134957314,\n",
       " (1, 34): 0.01609671488404274,\n",
       " (0, 32): 0.01602380412320296,\n",
       " (2, 38): 0.016092289860049885,\n",
       " (1, 35): 0.01609567863245805,\n",
       " (0, 33): 0.016023430973291397,\n",
       " (0, 34): 0.016027415171265602,\n",
       " (4, 35): 0.016099463527401287,\n",
       " (1, 36): 0.01609498697022597,\n",
       " (2, 39): 0.016092124705513317,\n",
       " (0, 35): 0.01602474662164847,\n",
       " (0, 36): 0.016028421620527904,\n",
       " (0, 37): 0.01602460692326228,\n",
       " (3, 43): 0.01609489383796851,\n",
       " (0, 38): 0.016028669973214466,\n",
       " (4, 36): 0.01609925056497256,\n",
       " (0, 39): 0.016025735686222713,\n",
       " (3, 44): 0.016094772145152092,\n",
       " (0, 40): 0.016028514752785366,\n",
       " (4, 37): 0.0160991537074248,\n",
       " (3, 45): 0.016095655038952827,\n",
       " (3, 46): 0.01609541413684686,\n",
       " (4, 38): 0.01609911024570465,\n",
       " (1, 37): 0.01609562647839387,\n",
       " (4, 39): 0.016098899766802788,\n",
       " (0, 41): 0.016025102386871975,\n",
       " (4, 40): 0.01609891715149085,\n",
       " (2, 40): 0.016092816988627117,\n",
       " (1, 38): 0.01609591270486514,\n",
       " (0, 42): 0.01602916729946931,\n",
       " (0, 43): 0.016030433277289074,\n",
       " (4, 41): 0.016098905354738235,\n",
       " (2, 41): 0.016092903912067413,\n",
       " (2, 42): 0.016092022880911827,\n",
       " (1, 39): 0.01609485906859239,\n",
       " (3, 47): 0.016095605368415516,\n",
       " (4, 42): 0.016098471979300182,\n",
       " (2, 43): 0.016091708714763325,\n",
       " (1, 40): 0.016094455495476723,\n",
       " (2, 44): 0.016092765455444653,\n",
       " (2, 45): 0.016092566152413685,\n",
       " (2, 46): 0.016091611857215565,\n",
       " (1, 41): 0.016095072651902836,\n",
       " (0, 44): 0.016026075929403305,\n",
       " (4, 43): 0.01609861229856809,\n",
       " (2, 47): 0.016092122842868168,\n",
       " (4, 44): 0.016098283231258392,\n",
       " (0, 45): 0.01602950009206931,\n",
       " (3, 48): 0.016095297411084175,\n",
       " (1, 42): 0.016094279165069263,\n",
       " (0, 46): 0.016026637827356655,\n",
       " (2, 48): 0.01609256366888682,\n",
       " (4, 45): 0.01609804853796959,\n",
       " (1, 43): 0.016094986349344254,\n",
       " (1, 44): 0.016093827784061432,\n",
       " (4, 46): 0.01609831303358078,\n",
       " (1, 45): 0.016094472259283066,\n",
       " (0, 47): 0.016024939715862274,\n",
       " (3, 49): 0.01609436236321926,\n",
       " (4, 47): 0.016098283231258392,\n",
       " (4, 48): 0.0160978560646375,\n",
       " (3, 50): 0.01609470136463642,\n",
       " (4, 49): 0.01609801563123862,\n",
       " (2, 49): 0.01609259843826294,\n",
       " (0, 48): 0.016028620302677155,\n",
       " (4, 50): 0.01609763316810131,\n",
       " (1, 46): 0.01609453248480956,\n",
       " (1, 47): 0.01609436919291814,\n",
       " (1, 48): 0.016094304000337917,\n",
       " (2, 50): 0.016091324388980865,\n",
       " (1, 49): 0.016093126808603603,\n",
       " (1, 50): 0.016092718889315922,\n",
       " (0, 49): 0.01602536377807458,\n",
       " (0, 50): 0.016029067958394688}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.047261593863368034, 0.07353825867176056, 0.04796862415969372, 0.06238468115528425, 0.04898064645628134], [0.01646471892793973, 0.016471896320581436, 0.016456063836812973, 0.016480324789881706, 0.016511892278989155], [0.016124846413731575, 0.016134091342488926, 0.01613809789220492, 0.01613425773878892, 0.016149551918109257], [0.016089300935467083, 0.01611370158692201, 0.01611182528237502, 0.016115390385190647, 0.01611912250518799], [0.01607208512723446, 0.01611176257332166, 0.016106193885207176, 0.016113239650925, 0.01611354077855746], [0.016055598855018616, 0.016110006719827652, 0.016103843227028847, 0.016110874091585476, 0.01611120191713174], [0.01604357734322548, 0.016108502944310505, 0.01610296592116356, 0.016109076639016468, 0.016109831631183624], [0.01603916970392068, 0.01610778955121835, 0.016101155430078506, 0.016107644885778427, 0.016108769923448563], [0.016034527371327083, 0.016106045494476955, 0.016100449487566948, 0.016107162460684776, 0.016108093162377674], [0.016025815159082413, 0.016105089336633682, 0.016100599740942318, 0.016106438512603443, 0.01610735182960828], [0.01602170802652836, 0.016104913627107937, 0.016100230316321056, 0.016105061396956444, 0.016106837739547093], [0.01602391277750333, 0.016103666896621387, 0.016098794216911, 0.01610425425072511, 0.01610609454413255], [0.01601955605049928, 0.016103433445096016, 0.016099095965425175, 0.016103491187095642, 0.01610553450882435], [0.016021714235345524, 0.016102366770307224, 0.016098707914352417, 0.016103729605674744, 0.01610504773755868], [0.016018298144141834, 0.016102229555447895, 0.01609833352267742, 0.01610312486688296, 0.016104744126399357], [0.016021158546209335, 0.016101224347949028, 0.01609798272450765, 0.01610178065796693, 0.016104223827521007], [0.016022102286418278, 0.016101305683453877, 0.01609782377878825, 0.01610223886867364, 0.016103758787115414], [0.016017965972423553, 0.01610095240175724, 0.016096683219075203, 0.0161011287321647, 0.01610366255044937], [0.016022140781084698, 0.016100631405909855, 0.016096895560622215, 0.016101187095046043, 0.016103238488237064], [0.016023181999723118, 0.016100209206342697, 0.016095848754048347, 0.016101228073239326, 0.016102822497487068], [0.016019633660713833, 0.016099905595183372, 0.01609630323946476, 0.01610098034143448, 0.01610265051325162], [0.01602316585679849, 0.016099516302347183, 0.016095322867234547, 0.016100674246748287, 0.016102325171232224], [0.016019873321056366, 0.016098512336611748, 0.01609582578142484, 0.01609940081834793, 0.0161019004881382], [0.0160237904638052, 0.016097840542594593, 0.016094659144679706, 0.01609984040260315, 0.016101909801363945], [0.01602596106628577, 0.016098394989967346, 0.01609458898504575, 0.01609973857800166, 0.016101722915967304], [0.01602703022460143, 0.016097574805219967, 0.01609536757071813, 0.016099287196993828, 0.01610119951268037], [0.01602780446410179, 0.01609793243308862, 0.016094292824467022, 0.01609921207030614, 0.016100910181800526], [0.016023656353354454, 0.01609800507624944, 0.0160936638712883, 0.01609901028374831, 0.01610068293909232], [0.016023047268390656, 0.016096976896127064, 0.016094734892249107, 0.016098552693923313, 0.016100474322835606], [0.016022053236762684, 0.016097243254383404, 0.01609487272799015, 0.016097474843263626, 0.016100590427716572], [0.01602700538933277, 0.016097145155072212, 0.016093431661526363, 0.016097843026121456, 0.016100533306598663], [0.01602380412320296, 0.016096959511439007, 0.016093942647178967, 0.016098016873002052, 0.016100314756234486], [0.016023430973291397, 0.016096688186128933, 0.016094326972961426, 0.01609696199496587, 0.01609981432557106], [0.016027415171265602, 0.01609671488404274, 0.016093943888942402, 0.016096441075205803, 0.016099572802583378], [0.01602474662164847, 0.01609567863245805, 0.01609294426937898, 0.016095889111359913, 0.016099463527401287], [0.016028421620527904, 0.01609498697022597, 0.016093389441569645, 0.01609599528213342, 0.01609925056497256], [0.01602460692326228, 0.01609562647839387, 0.016093404963612556, 0.016096627960602444, 0.0160991537074248], [0.016028669973214466, 0.01609591270486514, 0.016092289860049885, 0.016096560284495354, 0.01609911024570465], [0.016025735686222713, 0.01609485906859239, 0.016092124705513317, 0.016096757724881172, 0.016098899766802788], [0.016028514752785366, 0.016094455495476723, 0.016092816988627117, 0.01609570098419984, 0.01609891715149085], [0.016025102386871975, 0.016095072651902836, 0.016092903912067413, 0.01609630820651849, 0.016098905354738235], [0.01602916729946931, 0.016094279165069263, 0.016092022880911827, 0.016094962134957314, 0.016098471979300182], [0.016030433277289074, 0.016094986349344254, 0.016091708714763325, 0.01609489383796851, 0.01609861229856809], [0.016026075929403305, 0.016093827784061432, 0.016092765455444653, 0.016094772145152092, 0.016098283231258392], [0.01602950009206931, 0.016094472259283066, 0.016092566152413685, 0.016095655038952827, 0.01609804853796959], [0.016026637827356655, 0.01609453248480956, 0.016091611857215565, 0.01609541413684686, 0.01609831303358078], [0.016024939715862274, 0.01609436919291814, 0.016092122842868168, 0.016095605368415516, 0.016098283231258392], [0.016028620302677155, 0.016094304000337917, 0.01609256366888682, 0.016095297411084175, 0.0160978560646375], [0.01602536377807458, 0.016093126808603603, 0.01609259843826294, 0.01609436236321926, 0.01609801563123862], [0.016029067958394688, 0.016092718889315922, 0.016091324388980865, 0.01609470136463642, 0.01609763316810131]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x271dcc639d0>,\n",
       " <matplotlib.lines.Line2D at 0x271dcc637f0>,\n",
       " <matplotlib.lines.Line2D at 0x271dcc637c0>,\n",
       " <matplotlib.lines.Line2D at 0x271dcc63820>,\n",
       " <matplotlib.lines.Line2D at 0x271dcc63700>]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses2 = [[losses[(j,i)] for j in range(num_nodes) ] for i in range(1,epoch_total+1)]\n",
    "print(losses2)\n",
    "plt.plot(losses2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]C:\\Users\\ankit\\AppData\\Local\\Temp\\ipykernel_20060\\3311650527.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target_transform = lambda x: torch.nn.functional.one_hot(torch.tensor(x),62).float()\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[222], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m     loss \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mtrain_epoch()\n\u001b[0;32m      7\u001b[0m     epoch_losses\u001b[39m.\u001b[39mappend(loss)\n\u001b[1;32m----> 8\u001b[0m losses\u001b[39m.\u001b[39;49mappend(epoch_losses)\n\u001b[0;32m     12\u001b[0m av_state \u001b[39m=\u001b[39m {}\n\u001b[0;32m     16\u001b[0m states \u001b[39m=\u001b[39m [i\u001b[39m.\u001b[39mnetwork\u001b[39m.\u001b[39mstate_dict() \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m nodes]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for i in tqdm(range(5)):\n",
    "    epoch_losses = []\n",
    "    \n",
    "    for node in nodes:\n",
    "        loss = node.train_epoch()\n",
    "        epoch_losses.append(loss)\n",
    "    losses.append(epoch_losses)\n",
    "\n",
    "\n",
    "    \n",
    "    av_state = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    states = [i.network.state_dict() for i in nodes]\n",
    "    av_state = {}\n",
    "    for key in states[0]:\n",
    "        av_state[key] = sum([s[key] for s in states])/num_nodes\n",
    "    for node in nodes:\n",
    "        node.network.load_state_dict(av_state)\n",
    "\n",
    "time_FL = time.time() - start_time\n",
    "\n",
    "print(\"Time taken by FL without SMPC\", time_FL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Mean torch.Size([1, 28, 28])\n",
      "Global std  torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "global_mean = 0.0\n",
    "global_std = 0.0\n",
    "eqn1= 0.0 \n",
    "eqn2 = 0.0\n",
    "eqn3 = 0.0\n",
    "for node in nodes:\n",
    "    eqn1 += node.mean * node.dataset_size\n",
    "    eqn2 += node.dataset_size \n",
    "    eqn3 += node.std\n",
    "\n",
    "\n",
    "global_mean = eqn1/eqn2\n",
    "global_std = eqn3/eqn2\n",
    "print(\"Global Mean\", global_mean.shape)\n",
    "print(\"Global std \", global_std.shape)\n",
    "#plt.imshow(global_mean.squeeze())\n",
    "#plt.imshow(global_std.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Node  0\n",
      "Node Test Accuracy 15.384615384615385\n",
      "Node Test loss 4.100019454956055\n",
      "Node F1_Score  0.04102564102564103\n",
      "\n",
      "Node  1\n",
      "Node Test Accuracy 7.142857142857143\n",
      "Node Test loss 4.109908580780029\n",
      "Node F1_Score  0.009523809523809525\n",
      "\n",
      "Node  2\n",
      "Node Test Accuracy 9.75609756097561\n",
      "Node Test loss 4.109867095947266\n",
      "Node F1_Score  0.017344173441734414\n",
      "\n",
      "Node  3\n",
      "Node Test Accuracy 5.0\n",
      "Node Test loss 4.10900354385376\n",
      "Node F1_Score  0.0047619047619047615\n",
      "\n",
      "Node  4\n",
      "Node Test Accuracy 6.25\n",
      "Node Test loss 4.108822345733643\n",
      "Node F1_Score  0.007352941176470588\n"
     ]
    }
   ],
   "source": [
    "#nodes = [FederatedNode(l, i) for i,l in enumerate(test_loaders)]\n",
    "\n",
    "test_losses = []\n",
    "with torch.no_grad():\n",
    "    for i, node in enumerate(nodes):\n",
    "        print()\n",
    "        print(\"Node \", i)\n",
    "        node.testing()\n",
    "        #test_losses.append(node.test_loss)\n",
    "        print(\"Node Test Accuracy\", node.test_accuracy)\n",
    "        print(\"Node Test loss\", node.test_loss)\n",
    "        print(\"Node F1_Score \", node.f1_score)\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
